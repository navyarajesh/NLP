{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Part 1"
      ],
      "metadata": {
        "id": "NJzwNzC3rqFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMDB Sentiment Classification\n",
        "# GloVe & RNN/LSTM\n",
        "\n",
        "\n",
        "!pip install kagglehub --quiet\n",
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# 1. Download IMDB Dataset from Kaggle\n",
        "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "csv_path = os.path.join(path, \"IMDB Dataset.csv\")\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# 2. Preprocess text\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"<.*?>\", \" \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z']\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "df['review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# Tokenize\n",
        "tokenized_reviews = [word_tokenize(review) for review in df['review']]\n",
        "\n",
        "# Build vocab\n",
        "from collections import Counter\n",
        "word_counts = Counter(word for review in tokenized_reviews for word in review)\n",
        "vocab = {word: i+2 for i, (word, _) in enumerate(word_counts.most_common(30000))}\n",
        "vocab['<PAD>'] = 0\n",
        "vocab['<UNK>'] = 1\n",
        "\n",
        "# Encode reviews\n",
        "def encode_review(tokens):\n",
        "    return [vocab.get(token, vocab['<UNK>']) for token in tokens]\n",
        "\n",
        "encoded_reviews = [encode_review(tokens) for tokens in tokenized_reviews]\n",
        "\n",
        "# Pad sequences\n",
        "MAX_LEN = 200\n",
        "def pad_sequence(seq):\n",
        "    if len(seq) < MAX_LEN:\n",
        "        return seq + [vocab['<PAD>']] * (MAX_LEN - len(seq))\n",
        "    else:\n",
        "        return seq[:MAX_LEN]\n",
        "\n",
        "padded_reviews = np.array([pad_sequence(seq) for seq in encoded_reviews])\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(df['sentiment'])\n",
        "\n",
        "# Train/val/test split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(padded_reviews, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# 3. Load GloVe Embeddings\n",
        "!wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip -d glove\n",
        "\n",
        "embedding_dim = 100\n",
        "glove_path = f\"glove/glove.6B.{embedding_dim}d.txt\"\n",
        "\n",
        "glove_embeddings = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocab), embedding_dim))\n",
        "embedding_matrix[vocab['<PAD>']] = np.zeros((embedding_dim,))\n",
        "\n",
        "for word, idx in vocab.items():\n",
        "    vec = glove_embeddings.get(word)\n",
        "    if vec is not None:\n",
        "        embedding_matrix[idx] = vec\n",
        "\n",
        "# 4. Dataset & DataLoader\n",
        "class IMDBDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_loader = DataLoader(IMDBDataset(X_train, y_train), batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(IMDBDataset(X_val, y_val), batch_size=64)\n",
        "test_loader = DataLoader(IMDBDataset(X_test, y_test), batch_size=64)\n",
        "\n",
        "# 5. Model\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim, rnn_type=\"RNN\", embedding_weights=None, trainable=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        if embedding_weights is not None:\n",
        "            self.embedding.weight = nn.Parameter(torch.tensor(embedding_weights, dtype=torch.float32))\n",
        "            self.embedding.weight.requires_grad = trainable\n",
        "        if rnn_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.rnn(embedded)\n",
        "        last_output = output[:, -1, :]\n",
        "        return self.fc(last_output)\n",
        "\n",
        "# 6. Training loop\n",
        "def train_model(model, train_loader, val_loader, epochs=5, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "        val_acc = evaluate(model, val_loader)\n",
        "        print(f\"Epoch {epoch+1}: train_loss={total_loss/len(train_loader):.4f} | train_acc={correct/total:.4f} | val_acc={val_acc:.4f}\")\n",
        "    return evaluate(model, test_loader)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            preds = outputs.argmax(1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# 7. Run experiments\n",
        "results = {}\n",
        "\n",
        "print(\"\\n=== GloVe + Vanilla RNN ===\")\n",
        "model = RNNClassifier(len(vocab), embedding_dim, 128, 2, \"RNN\", embedding_matrix, trainable=False)\n",
        "results[\"GloVe + RNN\"] = train_model(model, train_loader, val_loader)\n",
        "\n",
        "print(\"\\n=== GloVe + LSTM ===\")\n",
        "model = RNNClassifier(len(vocab), embedding_dim, 128, 2, \"LSTM\", embedding_matrix, trainable=False)\n",
        "results[\"GloVe + LSTM\"] = train_model(model, train_loader, val_loader)\n",
        "\n",
        "print(\"\\n=== Random Embedding + RNN ===\")\n",
        "model = RNNClassifier(len(vocab), embedding_dim, 128, 2, \"RNN\", None, trainable=True)\n",
        "results[\"Random + RNN\"] = train_model(model, train_loader, val_loader)\n",
        "\n",
        "print(\"\\n=== Random Embedding + LSTM ===\")\n",
        "model = RNNClassifier(len(vocab), embedding_dim, 128, 2, \"LSTM\", None, trainable=True)\n",
        "results[\"Random + LSTM\"] = train_model(model, train_loader, val_loader)\n",
        "\n",
        "# 8. Final summary\n",
        "print(\"\\n=== Final Accuracy Summary ===\")\n",
        "for k, v in results.items():\n",
        "    print(f\"{k:25} Test Accuracy: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPXSaDAilpIx",
        "outputId": "1370ef2c-fd47-4709-8b69-7bf8a3a44543"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/imdb-dataset-of-50k-movie-reviews\n",
            "\n",
            "=== GloVe + Vanilla RNN ===\n",
            "Epoch 1: train_loss=0.6916 | train_acc=0.5248 | val_acc=0.5163\n",
            "Epoch 2: train_loss=0.6946 | train_acc=0.5113 | val_acc=0.4968\n",
            "Epoch 3: train_loss=0.6953 | train_acc=0.5133 | val_acc=0.4933\n",
            "Epoch 4: train_loss=0.6940 | train_acc=0.5156 | val_acc=0.5219\n",
            "Epoch 5: train_loss=0.6936 | train_acc=0.5192 | val_acc=0.5199\n",
            "\n",
            "=== GloVe + LSTM ===\n",
            "Epoch 1: train_loss=0.6884 | train_acc=0.5358 | val_acc=0.5769\n",
            "Epoch 2: train_loss=0.6802 | train_acc=0.5509 | val_acc=0.5287\n",
            "Epoch 3: train_loss=0.6112 | train_acc=0.6472 | val_acc=0.8028\n",
            "Epoch 4: train_loss=0.3908 | train_acc=0.8277 | val_acc=0.8295\n",
            "Epoch 5: train_loss=0.3578 | train_acc=0.8421 | val_acc=0.8432\n",
            "\n",
            "=== Random Embedding + RNN ===\n",
            "Epoch 1: train_loss=0.6978 | train_acc=0.5023 | val_acc=0.5119\n",
            "Epoch 2: train_loss=0.6907 | train_acc=0.5256 | val_acc=0.5232\n",
            "Epoch 3: train_loss=0.6919 | train_acc=0.5248 | val_acc=0.5363\n",
            "Epoch 4: train_loss=0.6800 | train_acc=0.5496 | val_acc=0.5229\n",
            "Epoch 5: train_loss=0.6581 | train_acc=0.5753 | val_acc=0.5303\n",
            "\n",
            "=== Random Embedding + LSTM ===\n",
            "Epoch 1: train_loss=0.6936 | train_acc=0.5154 | val_acc=0.5252\n",
            "Epoch 2: train_loss=0.6814 | train_acc=0.5481 | val_acc=0.5787\n",
            "Epoch 3: train_loss=0.6415 | train_acc=0.6324 | val_acc=0.7092\n",
            "Epoch 4: train_loss=0.4757 | train_acc=0.7813 | val_acc=0.8273\n",
            "Epoch 5: train_loss=0.3039 | train_acc=0.8762 | val_acc=0.8457\n",
            "\n",
            "=== Final Accuracy Summary ===\n",
            "GloVe + RNN               Test Accuracy: 0.5241\n",
            "GloVe + LSTM              Test Accuracy: 0.8441\n",
            "Random + RNN              Test Accuracy: 0.5305\n",
            "Random + LSTM             Test Accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "JeFbuzM1pz3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Month mapping\n",
        "MONTHS = {\n",
        "    'january': '01', 'jan': '01',\n",
        "    'february': '02', 'feb': '02',\n",
        "    'march': '03', 'mar': '03',\n",
        "    'april': '04', 'apr': '04',\n",
        "    'may': '05',\n",
        "    'june': '06', 'jun': '06',\n",
        "    'july': '07', 'jul': '07',\n",
        "    'august': '08', 'aug': '08',\n",
        "    'september': '09', 'sep': '09', 'sept': '09',\n",
        "    'october': '10', 'oct': '10',\n",
        "    'november': '11', 'nov': '11',\n",
        "    'december': '12', 'dec': '12'\n",
        "}\n",
        "\n",
        "def normalize_year(y):\n",
        "    \"\"\"Convert 2-digit year to 4-digit.\"\"\"\n",
        "    y = int(y)\n",
        "    if y < 100:\n",
        "        if y <= 25:  # assume 2000s\n",
        "            y += 2000\n",
        "        else:  # assume 1900s\n",
        "            y += 1900\n",
        "    return str(y)\n",
        "\n",
        "def parse_date(text):\n",
        "    text = text.lower().strip()\n",
        "\n",
        "    # 1. YYYY-MM-DD or YYYY/MM/DD or YYYY.MM.DD\n",
        "    m = re.search(r'(\\d{4})[-/.](\\d{1,2})[-/.](\\d{1,2})', text)\n",
        "    if m:\n",
        "        y, mo, d = m.groups()\n",
        "        return f\"{int(d):02d}/{int(mo):02d}/{y}\"\n",
        "\n",
        "    # 2. DD-MM-YYYY or DD/MM/YYYY or DD.MM.YYYY\n",
        "    m = re.search(r'(\\d{1,2})[-/.](\\d{1,2})[-/.](\\d{4})', text)\n",
        "    if m:\n",
        "        d, mo, y = m.groups()\n",
        "        return f\"{int(d):02d}/{int(mo):02d}/{y}\"\n",
        "\n",
        "    # 3. DD-MM-YY or DD/MM/YY or DD.MM.YY\n",
        "    m = re.search(r'(\\d{1,2})[-/.](\\d{1,2})[-/.](\\d{2})', text)\n",
        "    if m:\n",
        "        d, mo, y = m.groups()\n",
        "        return f\"{int(d):02d}/{int(mo):02d}/{normalize_year(y)}\"\n",
        "\n",
        "    # 4. Month name formats (e.g., \"5 March 2023\" or \"25th Dec 2024\")\n",
        "    m = re.search(r'(\\d{1,2})(?:st|nd|rd|th)?(?:\\s+of)?\\s+([a-zA-Z]+)[,]?\\s+(\\d{2,4})', text)\n",
        "    if m:\n",
        "        d, month_word, y = m.groups()\n",
        "        mo = MONTHS.get(month_word.lower()[:3], '??')\n",
        "        return f\"{int(d):02d}/{mo}/{normalize_year(y)}\"\n",
        "\n",
        "    m = re.search(r'([a-zA-Z]+)\\s+(\\d{1,2}),?\\s+(\\d{2,4})', text)\n",
        "    if m:\n",
        "        month_word, d, y = m.groups()\n",
        "        mo = MONTHS.get(month_word.lower()[:3], '??')\n",
        "        return f\"{int(d):02d}/{mo}/{normalize_year(y)}\"\n",
        "\n",
        "    return None\n",
        "\n",
        "# === Test on given CSV ===\n",
        "df = pd.read_csv(\"date_parser_testcases (1).csv\")\n",
        "df[\"Parsed Output\"] = df[\"Input\"].apply(parse_date)\n",
        "df[\"Match\"] = df[\"Parsed Output\"] == df[\"Expected Output\"]\n",
        "\n",
        "print(df)\n",
        "print(\"\\nAccuracy:\", df[\"Match\"].mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxymBtxdp1wG",
        "outputId": "e8b3edb6-3a7d-4ac4-b01a-4002fa4aef5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Input Expected Output  \\\n",
            "0         The event will take place on March 5, 2023.      05/03/2023   \n",
            "1                      Her birthday is on 07/08/1990.      07/08/1990   \n",
            "2                         The deadline is 2022-12-31.      31/12/2022   \n",
            "3                      We met on 1st of January 2000.      01/01/2000   \n",
            "4   The concert is scheduled for 15th September, 2...      15/09/2021   \n",
            "..                                                ...             ...   \n",
            "95  We celebrate Independence Day on 2023-07-04, a...      04/07/2023   \n",
            "96  The final date for submission is 30th November...      30/11/2022   \n",
            "97  The annual conference is on 15th October 2023,...      15/10/2023   \n",
            "98  His birthdate, noted as 1990-05-20, is in the ...      20/05/1990   \n",
            "99  The festival will be celebrated on 12th August...      12/08/2024   \n",
            "\n",
            "   Parsed Output  Match  \n",
            "0     05/03/2023   True  \n",
            "1     07/08/1990   True  \n",
            "2     31/12/2022   True  \n",
            "3     01/01/2000   True  \n",
            "4     15/09/2021   True  \n",
            "..           ...    ...  \n",
            "95    04/07/2023   True  \n",
            "96    30/11/2022   True  \n",
            "97    15/10/2023   True  \n",
            "98    20/05/1990   True  \n",
            "99    12/08/2024   True  \n",
            "\n",
            "[100 rows x 4 columns]\n",
            "\n",
            "Accuracy: 0.81\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3"
      ],
      "metadata": {
        "id": "LEVF0Depqq0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Pronoun mappings with dependency context\n",
        "male_to_female = {\n",
        "    \"he\": \"she\",\n",
        "    \"him\": \"her\",\n",
        "    \"his\": {\"poss\": \"her\", \"other\": \"his\"},\n",
        "    \"himself\": \"herself\"\n",
        "}\n",
        "\n",
        "female_to_male = {\n",
        "    \"she\": \"he\",\n",
        "    \"her\": {\"poss\": \"his\", \"other\": \"him\"},\n",
        "    \"hers\": \"his\",\n",
        "    \"herself\": \"himself\"\n",
        "}\n",
        "\n",
        "def preserve_case(word, replacement):\n",
        "    if word.isupper():\n",
        "        return replacement.upper()\n",
        "    elif word[0].isupper():\n",
        "        return replacement.capitalize()\n",
        "    else:\n",
        "        return replacement.lower()\n",
        "\n",
        "def replace_pronouns(text, target_gender):\n",
        "    doc = nlp(text)\n",
        "    new_tokens = []\n",
        "\n",
        "    for tok in doc:\n",
        "        lw = tok.text.lower()\n",
        "\n",
        "        if target_gender == \"female\" and lw in male_to_female:\n",
        "            if lw == \"his\":\n",
        "                replacement = male_to_female[\"his\"][\"poss\"] if tok.dep_ == \"poss\" else male_to_female[\"his\"][\"other\"]\n",
        "            else:\n",
        "                replacement = male_to_female[lw]\n",
        "            new_tokens.append(preserve_case(tok.text, replacement) + tok.whitespace_)\n",
        "\n",
        "        elif target_gender == \"male\" and lw in female_to_male:\n",
        "            if lw == \"her\":\n",
        "                replacement = female_to_male[\"her\"][\"poss\"] if tok.dep_ == \"poss\" else female_to_male[\"her\"][\"other\"]\n",
        "            else:\n",
        "                replacement = female_to_male[lw]\n",
        "            new_tokens.append(preserve_case(tok.text, replacement) + tok.whitespace_)\n",
        "\n",
        "        else:\n",
        "            new_tokens.append(tok.text_with_ws)\n",
        "\n",
        "    return \"\".join(new_tokens).strip()\n",
        "\n",
        "# Load test cases\n",
        "df = pd.read_csv(\"pronoun_testcases.csv\")\n",
        "\n",
        "# Apply transformation\n",
        "df[\"parsed_output\"] = df.apply(lambda row: replace_pronouns(row[\"input_text\"], row[\"target_gender\"]), axis=1)\n",
        "df[\"match\"] = df[\"parsed_output\"] == df[\"expected_output\"]\n",
        "\n",
        "# Results\n",
        "print(df[[\"input_text\", \"expected_output\", \"parsed_output\", \"match\"]])\n",
        "print(f\"Accuracy: {df['match'].mean() * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po7I1clDrIea",
        "outputId": "0715a5cd-3073-463c-82d6-bbdef9c1f3bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             input_text                      expected_output  \\\n",
            "0            He is going to the market.          She is going to the market.   \n",
            "1             His book is on the table.            Her book is on the table.   \n",
            "2                  I saw him yesterday.                 I saw her yesterday.   \n",
            "3                      He hurt himself.                    She hurt herself.   \n",
            "4              I called him last night.             I called her last night.   \n",
            "5                      That is his car.                     That is her car.   \n",
            "6            He told me about his trip.          She told me about her trip.   \n",
            "7       The teacher gave him a warning.      The teacher gave her a warning.   \n",
            "8    He blames himself for the mistake.  She blames herself for the mistake.   \n",
            "9                He brought his laptop.              She brought her laptop.   \n",
            "10                  He made it himself.                 She made it herself.   \n",
            "11           I don’t like his attitude.           I don’t like her attitude.   \n",
            "12               Tell him to come here.               Tell her to come here.   \n",
            "13          She is going to the market.           He is going to the market.   \n",
            "14            Her book is on the table.            His book is on the table.   \n",
            "15                 I saw her yesterday.                 I saw him yesterday.   \n",
            "16                    She hurt herself.                     He hurt himself.   \n",
            "17             I called her last night.             I called him last night.   \n",
            "18                     That is her car.                     That is his car.   \n",
            "19          She told me about her trip.           He told me about his trip.   \n",
            "20      The teacher gave her a warning.      The teacher gave him a warning.   \n",
            "21  She blames herself for the mistake.   He blames himself for the mistake.   \n",
            "22              She brought her laptop.               He brought his laptop.   \n",
            "23                 She made it herself.                  He made it himself.   \n",
            "24           I don’t like her attitude.           I don’t like his attitude.   \n",
            "25               Tell her to come here.               Tell him to come here.   \n",
            "\n",
            "                          parsed_output  match  \n",
            "0           She is going to the market.   True  \n",
            "1             Her book is on the table.   True  \n",
            "2                  I saw her yesterday.   True  \n",
            "3                     She hurt herself.   True  \n",
            "4              I called her last night.   True  \n",
            "5                      That is her car.   True  \n",
            "6           She told me about her trip.   True  \n",
            "7       The teacher gave her a warning.   True  \n",
            "8   She blames herself for the mistake.   True  \n",
            "9               She brought her laptop.   True  \n",
            "10                 She made it herself.   True  \n",
            "11           I don’t like her attitude.   True  \n",
            "12               Tell her to come here.   True  \n",
            "13           He is going to the market.   True  \n",
            "14            His book is on the table.   True  \n",
            "15                 I saw him yesterday.   True  \n",
            "16                     He hurt himself.   True  \n",
            "17             I called him last night.   True  \n",
            "18                     That is his car.   True  \n",
            "19           He told me about his trip.   True  \n",
            "20      The teacher gave him a warning.   True  \n",
            "21   He blames himself for the mistake.   True  \n",
            "22               He brought his laptop.   True  \n",
            "23                  He made it himself.   True  \n",
            "24           I don’t like his attitude.   True  \n",
            "25               Tell him to come here.   True  \n",
            "Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just another way:\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Separate mappings\n",
        "male_to_female = {\n",
        "    \"he\": \"she\",\n",
        "    \"him\": \"her\",\n",
        "    \"his\": \"her\",       # will handle possessive separately\n",
        "    \"himself\": \"herself\"\n",
        "}\n",
        "\n",
        "female_to_male = {\n",
        "    \"she\": \"he\",\n",
        "    \"her\": \"him\",       # will handle possessive separately\n",
        "    \"hers\": \"his\",\n",
        "    \"herself\": \"himself\"\n",
        "}\n",
        "\n",
        "def preserve_case(word, replacement):\n",
        "    if word.isupper():\n",
        "        return replacement.upper()\n",
        "    elif word[0].isupper():\n",
        "        return replacement.capitalize()\n",
        "    else:\n",
        "        return replacement.lower()\n",
        "\n",
        "def replace_pronouns(text, target_gender):\n",
        "    words = re.findall(r\"\\w+|[^\\w\\s]\", text)\n",
        "    new_words = []\n",
        "\n",
        "    for i, w in enumerate(words):\n",
        "        lw = w.lower()\n",
        "\n",
        "        if target_gender == \"female\" and lw in male_to_female:\n",
        "            # special case for \"his\"\n",
        "            if lw == \"his\":\n",
        "                if i + 1 < len(words) and words[i+1].isalpha():\n",
        "                    replacement = \"her\"  # possessive adjective\n",
        "                else:\n",
        "                    replacement = \"hers\" # possessive pronoun\n",
        "            else:\n",
        "                replacement = male_to_female[lw]\n",
        "            new_words.append(preserve_case(w, replacement))\n",
        "\n",
        "        elif target_gender == \"male\" and lw in female_to_male:\n",
        "            # special case for \"her\"\n",
        "            if lw == \"her\":\n",
        "                if i + 1 < len(words) and words[i+1].isalpha():\n",
        "                    replacement = \"his\"  # possessive adjective\n",
        "                else:\n",
        "                    replacement = \"him\"  # object pronoun\n",
        "            else:\n",
        "                replacement = female_to_male[lw]\n",
        "            new_words.append(preserve_case(w, replacement))\n",
        "\n",
        "        else:\n",
        "            new_words.append(w)\n",
        "\n",
        "    # Join keeping punctuation spacing correct\n",
        "    return \"\".join(\n",
        "        [\" \" + w if i > 0 and re.match(r\"\\w\", w) and re.match(r\"\\w\", new_words[i-1]) else w\n",
        "         for i, w in enumerate(new_words)]\n",
        "    )\n",
        "\n",
        "# Load and test\n",
        "df = pd.read_csv(\"pronoun_testcases.csv\")\n",
        "df[\"parsed_output\"] = df.apply(lambda row: replace_pronouns(row[\"input_text\"], row[\"target_gender\"]), axis=1)\n",
        "df[\"match\"] = df[\"parsed_output\"] == df[\"expected_output\"]\n",
        "\n",
        "print(df[[\"input_text\", \"expected_output\", \"parsed_output\", \"match\"]])\n",
        "print(f\"Accuracy: {df['match'].mean() * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj3dIcl1qr8H",
        "outputId": "dd051962-ae67-463a-d199-7c4ba7f09c70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             input_text                      expected_output  \\\n",
            "0            He is going to the market.          She is going to the market.   \n",
            "1             His book is on the table.            Her book is on the table.   \n",
            "2                  I saw him yesterday.                 I saw her yesterday.   \n",
            "3                      He hurt himself.                    She hurt herself.   \n",
            "4              I called him last night.             I called her last night.   \n",
            "5                      That is his car.                     That is her car.   \n",
            "6            He told me about his trip.          She told me about her trip.   \n",
            "7       The teacher gave him a warning.      The teacher gave her a warning.   \n",
            "8    He blames himself for the mistake.  She blames herself for the mistake.   \n",
            "9                He brought his laptop.              She brought her laptop.   \n",
            "10                  He made it himself.                 She made it herself.   \n",
            "11           I don’t like his attitude.           I don’t like her attitude.   \n",
            "12               Tell him to come here.               Tell her to come here.   \n",
            "13          She is going to the market.           He is going to the market.   \n",
            "14            Her book is on the table.            His book is on the table.   \n",
            "15                 I saw her yesterday.                 I saw him yesterday.   \n",
            "16                    She hurt herself.                     He hurt himself.   \n",
            "17             I called her last night.             I called him last night.   \n",
            "18                     That is her car.                     That is his car.   \n",
            "19          She told me about her trip.           He told me about his trip.   \n",
            "20      The teacher gave her a warning.      The teacher gave him a warning.   \n",
            "21  She blames herself for the mistake.   He blames himself for the mistake.   \n",
            "22              She brought her laptop.               He brought his laptop.   \n",
            "23                 She made it herself.                  He made it himself.   \n",
            "24           I don’t like her attitude.           I don’t like his attitude.   \n",
            "25               Tell her to come here.               Tell him to come here.   \n",
            "\n",
            "                          parsed_output  match  \n",
            "0           She is going to the market.   True  \n",
            "1             Her book is on the table.   True  \n",
            "2                  I saw her yesterday.   True  \n",
            "3                     She hurt herself.   True  \n",
            "4              I called her last night.   True  \n",
            "5                      That is her car.   True  \n",
            "6           She told me about her trip.   True  \n",
            "7       The teacher gave her a warning.   True  \n",
            "8   She blames herself for the mistake.   True  \n",
            "9               She brought her laptop.   True  \n",
            "10                 She made it herself.   True  \n",
            "11           I don’t like her attitude.   True  \n",
            "12               Tell her to come here.   True  \n",
            "13           He is going to the market.   True  \n",
            "14            His book is on the table.   True  \n",
            "15                 I saw his yesterday.  False  \n",
            "16                     He hurt himself.   True  \n",
            "17             I called his last night.  False  \n",
            "18                     That is his car.   True  \n",
            "19           He told me about his trip.   True  \n",
            "20      The teacher gave his a warning.  False  \n",
            "21   He blames himself for the mistake.   True  \n",
            "22               He brought his laptop.   True  \n",
            "23                  He made it himself.   True  \n",
            "24           I don’t like his attitude.   True  \n",
            "25               Tell his to come here.  False  \n",
            "Accuracy: 84.62%\n"
          ]
        }
      ]
    }
  ]
}